{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ae8e171-fb92-4f03-a585-5dc077167b9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torchinfo import summary\n",
    "from torchvision import transforms, datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import utils\n",
    "import os\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "utils.set_seeds()\n",
    "\n",
    "#os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "print(torch.__version__)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6eecdfb-ead8-482a-955d-15f61d767986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "#LEARNING_RATE = 0.0001\n",
    "LEARNING_RATE = 0.001\n",
    "BATCH_SIZE = 1\n",
    "NUM_EPOCHS = 30\n",
    "schedule = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89ec54ef-a85b-4a21-964c-ae18cfbea8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_setup\n",
    "from torchvision import transforms\n",
    "\n",
    "simple_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(mode='F'),\n",
    "    transforms.CenterCrop((320, 320)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "aug_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(mode='F'),\n",
    "    # transforms.CenterCrop((360, 360)),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomResizedCrop(size=(320, 320), scale=(0.3,1), ratio=(1, 1)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_dir = '../picai/train/'\n",
    "test_dir = '../picai/test/'\n",
    "\n",
    "train_dataloader, test_dataloader = data_setup.create_dataloaders(train_dir=train_dir,\n",
    "                                                                  test_dir=test_dir,\n",
    "                                                                  train_transform=aug_transform, \n",
    "                                                                  test_transform=simple_transform, \n",
    "                                                                  batch_size=BATCH_SIZE\n",
    "                                                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9c49059-9101-4529-a0c9-e54a0688442f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import vnetrec_model\n",
    "\n",
    "model_name=\"vnet_rec_v0\"\n",
    "model = vnetrec_model.VNetRec(elu=True, se=True, input_ch=1, split_ch=4).to(device)\n",
    "#model = torch.load(\"./models/vnet_rec_v0_last_trained_epoch.pth\").to(device)\n",
    "model.name = model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c95ba2bf-1b58-4a5e-a459-2b09c93c4e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze parameters\n",
    "# i = 0\n",
    "# for param in model.parameters(): #120\n",
    "#     i += 1\n",
    "#     if i<30:\n",
    "#         param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c212ac6-aa30-43c6-849b-9644b0b48f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import simple_vit_seg\n",
    "\n",
    "# model = simple_vit_seg.SimpleSEGViT(\n",
    "#     image_size = 320,          # image size\n",
    "#     frames = 16,               # number of frames\n",
    "#     image_patch_size = 16,     # image patch size\n",
    "#     frame_patch_size = 1,      # frame patch size\n",
    "#     dim = 512,\n",
    "#     depth = 6,\n",
    "#     heads = 8,\n",
    "#     mlp_dim = 2048,\n",
    "#     channels = 1,\n",
    "#     mask_hidden_dim = 32\n",
    "# ).to(device)\n",
    "\n",
    "# model_name=\"vit_seg_organ_v0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7dd0a507-446f-4c13-95f6-5d2305bac58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create random input sizes\n",
    "# random_input_image = (4, 1, 320, 320, 16)\n",
    "# #random_input_image = (4, 1, 16, 320, 320)\n",
    "\n",
    "# # Get a summary of the input and outputs of PatchEmbedding (uncomment for full output)\n",
    "# summary(model,\n",
    "#         input_size=random_input_image, # try swapping this for \"random_input_image_error\"\n",
    "#         col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "#         col_width=20,\n",
    "#         row_settings=[\"var_names\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b7aaa19-bfe2-405e-a82e-6629d3838a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_input_image = torch.randn(BATCH_SIZE, 1, 320, 320, 16).to(device)\n",
    "\n",
    "# test_output = model(random_input_image)\n",
    "\n",
    "# test_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8bc34131-1347-42e7-9187-ec76db8e1e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.MSELoss(reduction='sum')\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                             betas = (0.9, 0.999),\n",
    "                             lr=LEARNING_RATE,\n",
    "                            #weight_decay=0.0001,\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc79f992-c02a-4522-bde9-6305d27dd99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import CyclicLR\n",
    "\n",
    "# step_size_up = 8*len(train_dataloader) # number of iterations per half-cycle, default 2000\n",
    "# lr_scheduler = CyclicLR(optimizer, base_lr=LEARNING_RATE/20, max_lr=LEARNING_RATE, step_size_up=step_size_up, mode='exp_range', cycle_momentum=False)\n",
    "\n",
    "if schedule == True:\n",
    "    lr_scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=LEARNING_RATE, epochs=NUM_EPOCHS, steps_per_epoch=len(train_dataloader))\n",
    "else:\n",
    "    lr_scheduler = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "511c2c3d-67a2-4a3f-950e-ecaba7ab38bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ## BEGIN TRAINING ## \n",
      "    Model:                 \t vnet_rec_v0\n",
      "    Number of train batches:\t 2517\n",
      "    Number of test batches:\t 769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37f301a557df4a18b62b3329dea6d157",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t 503 \t Loss: 2650371.5265 MAE: 1777053.1461\n",
      "\t 1006 \t Loss: 2604713.539 MAE: 1760952.1194\n",
      "\t 1509 \t Loss: 2560921.3012 MAE: 1743735.2201\n",
      "\t 2012 \t Loss: 2515869.217 MAE: 1725244.3125\n",
      "Epoch: 1 | train_loss: 2468481.8759 | train_bcloss: 1706674.4621 | test_loss: 2236841.8787 |  test_bcloss: 1598171.1746\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'train_bcloss'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mengine\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mengine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                         \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNUM_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mresults_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./results/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mmodels_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./models/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/rec_vnet_quality/engine.py:174\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_dataloader, test_dataloader, optimizer, lr_scheduler, criterion, epochs, results_path, models_path, device)\u001b[0m\n\u001b[1;32m    172\u001b[0m results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(epoch)\n\u001b[1;32m    173\u001b[0m results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(train_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m--> 174\u001b[0m \u001b[43mresults\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain_bcloss\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mappend(train_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmae\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    175\u001b[0m results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(test_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    176\u001b[0m results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_bcloss\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(test_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmae\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[0;31mKeyError\u001b[0m: 'train_bcloss'"
     ]
    }
   ],
   "source": [
    "import engine\n",
    "\n",
    "results = engine.train(model=model,\n",
    "                         train_dataloader=train_dataloader,\n",
    "                         test_dataloader=test_dataloader,\n",
    "                         optimizer=optimizer,\n",
    "                         lr_scheduler=lr_scheduler,\n",
    "                         criterion=criterion,\n",
    "                         epochs=NUM_EPOCHS,\n",
    "                         results_path=\"./results/\",\n",
    "                         models_path=\"./models/\",\n",
    "                         device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "779021cd-1a40-463b-aada-2871d5c9f40a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Saving model to: models/vnet_rec_v0_weights.pth\n"
     ]
    }
   ],
   "source": [
    "utils.save_model(model=model,\n",
    "               target_dir=\"./models/\",\n",
    "               model_name=model_name+\"_weights.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b542794-5fea-483f-ac60-4be4a54fd6bd",
   "metadata": {},
   "source": [
    "###### final test evaluation\n",
    "import engine\n",
    "\n",
    "test_results = engine.test_step(model=model,\n",
    "                         dataloader=test_dataloader,\n",
    "                         loss_fn=loss_fn,\n",
    "                         device=device)\n",
    "\n",
    "print(\n",
    "    f\"test_loss: {test_results['loss']:.4f} |  \"\n",
    "    f\"test_mae: {test_results['mae']:.4f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16217a98-db64-4ed0-a551-4f322117970c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
